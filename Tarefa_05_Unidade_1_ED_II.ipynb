{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorNGomes/Guided-Project-Building-Fast-Queries-on-a-CSV/blob/main/Tarefa_05_Unidade_1_ED_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guided Project: Building Fast Queries on a CSV\n",
        "- Adaptado do projeto guiado do curso Algorithm Complexity da plataforma [Dataquest](https://dataquest.io)\n",
        "- Usamos o dataset The Reddit Climate Change Dataset obtido por meio do [Kaggle](https://www.kaggle.com/datasets/pavellexyr/the-reddit-climate-change-dataset)\n",
        "- Desenvolvido por:\n",
        "  - Gabriel Lins ([GitHub](https://github.com/gabrielblins))\n",
        "  - Victor Gomes ([GitHub](https://github.com/victorngomes))"
      ],
      "metadata": {
        "id": "N0fvi9GBbSui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtendo dados do Kaggle"
      ],
      "metadata": {
        "id": "Iw1sGGFHNMbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.kaggle"
      ],
      "metadata": {
        "id": "8nfhz_kPMi08"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv kaggle.json /root/.kaggle"
      ],
      "metadata": {
        "id": "rmDEPQY0Mmqt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d pavellexyr/the-reddit-climate-change-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCe1M5k2MPfE",
        "outputId": "ffbaf3d2-dd27-469c-a7b1-129a6b58ab88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading the-reddit-climate-change-dataset.zip to /content\n",
            " 99% 1.49G/1.50G [00:13<00:00, 133MB/s]\n",
            "100% 1.50G/1.50G [00:13<00:00, 116MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip the-reddit-climate-change-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1KVFWQlMu8J",
        "outputId": "e362024d-f8bd-41ff-e042-cc1d5c070652"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  the-reddit-climate-change-dataset.zip\n",
            "  inflating: the-reddit-climate-change-dataset-comments.csv  \n",
            "  inflating: the-reddit-climate-change-dataset-posts.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm the-reddit-climate-change-dataset.zip"
      ],
      "metadata": {
        "id": "_wnoPbmWM1bx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição das funções e classes"
      ],
      "metadata": {
        "id": "ElsyrXP9NQ_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "  \n",
        "def read_csv(file_path):\n",
        "    with open(file_path) as f: \n",
        "        reader = csv.reader(f)\n",
        "        rows = list(reader)\n",
        "\n",
        "    for row in rows[1:]:\n",
        "      if len(row[-2]) is 0:\n",
        "        row[-2] = 0.0\n",
        "      else:\n",
        "        row[-2] = float(row[-2])\n",
        "\n",
        "    return rows\n"
      ],
      "metadata": {
        "id": "7gGCba3KtRYE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Searcher():\n",
        "    def __init__(self, csv):\n",
        "        self.header = csv[0]         \n",
        "        self.rows = csv[1:]\n",
        "        self.id_to_row = {}\n",
        "        for row in self.rows:\n",
        "            self.id_to_row[row[1]] = row  \n",
        "\n",
        "    def get_comment_from_id(self, id):   \n",
        "        for row in self.rows:\n",
        "            if row[self.header.index('id')] == id:\n",
        "                return row\n",
        "        return None\n",
        "\n",
        "    def get_comment_from_id_fast(self,id):\n",
        "        if id in self.id_to_row.keys():\n",
        "            return self.id_to_row[id] \n",
        "        return None                       \n",
        "      \n",
        "    def get_sentiment_in_range(self, bottom ,upper):\n",
        "        return [row for row in self.rows if row[-2] >= bottom and row[-2] <= upper]\n",
        "  \n",
        "    def twoScoreSum(self, targetSum):    \n",
        "        for row1 in self.rows:                     \n",
        "            for row2 in self.rows:\n",
        "                if float(row1[-1]) + float(row2[-1]) == targetSum:\n",
        "                    return [row1, row2]\n",
        "        return -1          \n",
        "\n",
        "    def twoScoreSum_fast(self,targetSum):\n",
        "        results = {}\n",
        "        for row in self.rows:\n",
        "            y = targetSum - float(row[-1])\n",
        "            if y in results:\n",
        "                return [results[y], row]\n",
        "            else:\n",
        "                results[float(row[-1])] = row\n",
        "        return -1"
      ],
      "metadata": {
        "id": "xq2NX0u7iOIK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Teste dos métodos implementados*"
      ],
      "metadata": {
        "id": "Nwqiq-q0rNRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_csv('the-reddit-climate-change-dataset-comments.csv')\n"
      ],
      "metadata": {
        "id": "SN5MyI4HjEKX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srch = Searcher(data)"
      ],
      "metadata": {
        "id": "SfKPepZiuis3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srch.rows[56]"
      ],
      "metadata": {
        "id": "vpgH0pgwTnTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44dfc969-6f54-4543-e7d7-87291f8f7181"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comment',\n",
              " 'iml9tsw',\n",
              " '2g3blu',\n",
              " 'coronavirusdownunder',\n",
              " 'false',\n",
              " '1661988796',\n",
              " 'https://old.reddit.com/r/CoronavirusDownunder/comments/x27ii7/antivaxxers_lose_in_federal_court_must_pay_200k/iml9tsw/',\n",
              " 'Just because someone has donated to a university doesn\\'t mean they have any say over the results of the research. Any scientist that intentionally publishes misleading information will destroy their entire career. The fact is that regardless of the results of any scientific research, there will be plenty of science left to do. \\n\\nIf we suddenly discovered that covid vaccines were unsafe (which they aren\\'t), it\\'s not like everyone would lose their jobs - in fact they\\'d have more work to do, and would receive even more funding to develop a vaccine that is safe. If they found that covid vaccines are perfectly safe (which they are), then there would still be more work to do developing future vaccines to be more effective, especially against newer variants.\\n\\nEssentially, the likelihood of a donation influencing the results of scientific research, and not having that be found out pretty quickly is exceptionally low. Remember when cigarette companies funded research that \"proved\" that smoking was safe? Also remember how all independent research disproved this? Same goes for fossil fuel companies funding research to \"prove\" that climate change isn\\'t real.',\n",
              " 0.8855,\n",
              " '4']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srch.header"
      ],
      "metadata": {
        "id": "7wJJe3y9oF2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5b46b3-e066-488d-9279-b1c57e2d367a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['type',\n",
              " 'id',\n",
              " 'subreddit.id',\n",
              " 'subreddit.name',\n",
              " 'subreddit.nsfw',\n",
              " 'created_utc',\n",
              " 'permalink',\n",
              " 'body',\n",
              " 'sentiment',\n",
              " 'score']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srch.get_comment_from_id('imld6cb')"
      ],
      "metadata": {
        "id": "TkKXdc4qkH9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b2f37b-f437-4d5d-8a8c-70fefc0ef5ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comment',\n",
              " 'imld6cb',\n",
              " '2qi09',\n",
              " 'sacramento',\n",
              " 'false',\n",
              " '1661990278',\n",
              " 'https://old.reddit.com/r/Sacramento/comments/x2ruqy/hey_guyz_this_is_a_tough_one_why_do_you_think/imld6cb/',\n",
              " \"Not just Sacramento. It's actually happening all over the world. Climate change is real, believe it or not.\",\n",
              " 0.0,\n",
              " '4']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srch.get_comment_from_id('iml9tsw')"
      ],
      "metadata": {
        "id": "uWChYIUO1KuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84732731-6431-496e-8081-4e0fd34223ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comment',\n",
              " 'iml9tsw',\n",
              " '2g3blu',\n",
              " 'coronavirusdownunder',\n",
              " 'false',\n",
              " '1661988796',\n",
              " 'https://old.reddit.com/r/CoronavirusDownunder/comments/x27ii7/antivaxxers_lose_in_federal_court_must_pay_200k/iml9tsw/',\n",
              " 'Just because someone has donated to a university doesn\\'t mean they have any say over the results of the research. Any scientist that intentionally publishes misleading information will destroy their entire career. The fact is that regardless of the results of any scientific research, there will be plenty of science left to do. \\n\\nIf we suddenly discovered that covid vaccines were unsafe (which they aren\\'t), it\\'s not like everyone would lose their jobs - in fact they\\'d have more work to do, and would receive even more funding to develop a vaccine that is safe. If they found that covid vaccines are perfectly safe (which they are), then there would still be more work to do developing future vaccines to be more effective, especially against newer variants.\\n\\nEssentially, the likelihood of a donation influencing the results of scientific research, and not having that be found out pretty quickly is exceptionally low. Remember when cigarette companies funded research that \"proved\" that smoking was safe? Also remember how all independent research disproved this? Same goes for fossil fuel companies funding research to \"prove\" that climate change isn\\'t real.',\n",
              " 0.8855,\n",
              " '4']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srch.get_comment_from_id_fast('imld6cb')"
      ],
      "metadata": {
        "id": "jr1B3YIiNKN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f819a6b-39e1-43f0-af02-5711bcb9f558"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comment',\n",
              " 'imld6cb',\n",
              " '2qi09',\n",
              " 'sacramento',\n",
              " 'false',\n",
              " '1661990278',\n",
              " 'https://old.reddit.com/r/Sacramento/comments/x2ruqy/hey_guyz_this_is_a_tough_one_why_do_you_think/imld6cb/',\n",
              " \"Not just Sacramento. It's actually happening all over the world. Climate change is real, believe it or not.\",\n",
              " 0.0,\n",
              " '4']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparando desempenho\n"
      ],
      "metadata": {
        "id": "FkbYJ_CRrfrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tempo de execuação para a função *get_comment_from_id* e *get_comment_from_id_fast*"
      ],
      "metadata": {
        "id": "IkjSE20Xah4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time                                                         \n",
        "from random import shuffle                                                    \n",
        "\n",
        "ids = [rows[1] for rows in srch.rows[:15]]\n",
        "shuffle(ids)\n",
        "print('################################################################')\n",
        "for id in ids:\n",
        "    print(id)\n",
        "    %timeit -n 100 srch.get_comment_from_id(id)\n",
        "    print('################################################################')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw8jE3qyn_B4",
        "outputId": "4b35584f-f8f0-4ccb-d6b5-95648be6d821"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################\n",
            "imldbeh\n",
            "600 ns ± 50.6 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlddn9\n",
            "384 ns ± 19.7 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imld0kj\n",
            "1.15 µs ± 39.2 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlctc0\n",
            "1.56 µs ± 74 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imld6cb\n",
            "1.01 µs ± 124 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imldado\n",
            "926 ns ± 381 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlch0h\n",
            "2.34 µs ± 137 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlc8w9\n",
            "2.81 µs ± 64.7 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlctri\n",
            "1.33 µs ± 62.7 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlcfv2\n",
            "2.44 µs ± 43.9 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlc7mr\n",
            "3 µs ± 31 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlcln1\n",
            "2.07 µs ± 36.8 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlca5e\n",
            "2.62 µs ± 37.5 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlcpab\n",
            "1.7 µs ± 45.4 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlcm07\n",
            "1.93 µs ± 99 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('################################################################')\n",
        "for id in ids:\n",
        "    print(id)\n",
        "    %timeit -n 100 srch.get_comment_from_id_fast(id)\n",
        "    print('################################################################')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um32u6Dr4yLx",
        "outputId": "068eb2c3-165a-4684-8a44-8f07166a1df0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################\n",
            "imldbeh\n",
            "482 ns ± 75.7 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlcpab\n",
            "245 ns ± 16.1 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlc7mr\n",
            "249 ns ± 25.4 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlcfv2\n",
            "272 ns ± 47 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlcm07\n",
            "299 ns ± 149 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlctri\n",
            "244 ns ± 10.9 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imld6cb\n",
            "242 ns ± 8.39 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlcln1\n",
            "242 ns ± 8.73 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlddn9\n",
            "271 ns ± 53.9 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imld0kj\n",
            "243 ns ± 7.9 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlca5e\n",
            "251 ns ± 8.24 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlc8w9\n",
            "242 ns ± 7.93 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlch0h\n",
            "270 ns ± 30.6 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imlctc0\n",
            "254 ns ± 25.1 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "imldado\n",
            "247 ns ± 7.55 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tempo de execuação para as funções twoScoreSum e thoScoreSum_fast"
      ],
      "metadata": {
        "id": "q5HrOV8r4HgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parametros = [4,27,70,100]\n",
        "print('################################################################')\n",
        "for param in parametros:\n",
        "    print(param)\n",
        "    %timeit -n 100 srch.twoScoreSum(param)\n",
        "    print('################################################################') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1XshhQd2YMK",
        "outputId": "f655762a-bab6-4dfe-ad4f-13b141baf32c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################\n",
            "4\n",
            "727 ns ± 40.4 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "27\n",
            "31.5 µs ± 14.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "70\n",
            "129 µs ± 22.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "100\n",
            "403 µs ± 20.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('################################################################')\n",
        "for param in parametros:\n",
        "    print(param)\n",
        "    %timeit -n 100 srch.twoScoreSum_fast(param)\n",
        "    print('################################################################') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVKpOtK64FqS",
        "outputId": "e865d81c-a887-498f-8bf0-7d0e3776891a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################\n",
            "4\n",
            "1.93 µs ± 167 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "27\n",
            "24.4 µs ± 5.25 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "70\n",
            "44 µs ± 3.17 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n",
            "100\n",
            "172 µs ± 11.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementando testes unitários com Pytest"
      ],
      "metadata": {
        "id": "0VoutLyXamGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXN56zOLPLso",
        "outputId": "7c48f0cc-aeca-4759-d32e-156cd4a5b009"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (8.14.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.4.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (22.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest) (57.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.11.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file test_data.py\n",
        "import pytest\n",
        "import csv\n",
        "import pickle\n",
        "  \n",
        "def read_csv(file_path):\n",
        "    with open(file_path) as f: \n",
        "        reader = csv.reader(f)\n",
        "        rows = list(reader)\n",
        "\n",
        "    for row in rows[1:]:\n",
        "      if len(row[-2]) is 0:\n",
        "        row[-2] = 0.0\n",
        "      else:\n",
        "        row[-2] = float(row[-2])\n",
        "\n",
        "    return rows\n",
        "\n",
        "class Searcher():\n",
        "    def __init__(self, csv):\n",
        "        self.header = csv[0]         \n",
        "        self.rows = csv[1:]\n",
        "        self.id_to_row = {}\n",
        "        for row in self.rows:\n",
        "            self.id_to_row[row[1]] = row  \n",
        "\n",
        "    def get_comment_from_id(self, id):   \n",
        "        for row in self.rows:\n",
        "            if row[self.header.index('id')] == id:\n",
        "                return row\n",
        "        return None\n",
        "\n",
        "    def get_comment_from_id_fast(self,id):\n",
        "        if id in self.id_to_row.keys():\n",
        "            return self.id_to_row[id] \n",
        "        return None                      \n",
        "      \n",
        "    def get_sentiment_in_range(self, bottom ,upper):\n",
        "        return [row for row in self.rows if row[-2] >= bottom and row[-2] <= upper]\n",
        "  \n",
        "    def twoScoreSum(self, targetSum):    \n",
        "        for row1 in self.rows:                     \n",
        "            for row2 in self.rows:\n",
        "                if float(row1[-1]) + float(row2[-1]) == targetSum:\n",
        "                    return [row1, row2]\n",
        "        return -1          \n",
        "\n",
        "    def twoScoreSum_fast(self,targetSum):\n",
        "        results = {}\n",
        "        for row in self.rows:\n",
        "            y = targetSum - float(row[-1])\n",
        "            if y in results:\n",
        "                return [results[y], row]\n",
        "            else:\n",
        "                results[float(row[-1])] = row\n",
        "        return -1\n",
        "\n",
        "arquivo = 'the-reddit-climate-change-dataset-comments.csv'\n",
        "\n",
        "twoscoresum_result = [\n",
        "    ['comment',\n",
        "    'imlddn9',\n",
        "    '2qh3l',\n",
        "    'news',\n",
        "    'false',\n",
        "    '1661990368',\n",
        "    'https://old.reddit.com/r/news/comments/x2cszk/us_life_expectancy_down_for_secondstraight_year/imlddn9/',\n",
        "    'Yeah but what the above commenter is saying is their base doesn’t want any of that. They detest all of those things, even the small gradual changes. Investing in nuclear energy is a tacit acknowledgement of man made climate change. Any acknowledgement or concession and they will be primaried out in a minute',\n",
        "    0.5719,\n",
        "    '2'],\n",
        "    ['comment',\n",
        "    'iml68pg',\n",
        "    '2qh1n',\n",
        "    'environment',\n",
        "    'false',\n",
        "    '1661987214',\n",
        "    'https://old.reddit.com/r/environment/comments/x2d6mk/climate_scientists_urge_more_civil_disobedience/iml68pg/',\n",
        "    \"I'm all for protests as long as they don't involve damage of people or property. Despite the fact that I value this world and its living things more than any and all property if we go around smashing stuff it's just going to corrupt the important message and turn people against it and us.\\n\\nEveryone needs to come together on climate change and we need to educate climate change deniers rather than shout them down or insult them and especially never try to hurt them.\\n\\nA united human race is what is required to help the Earth and we won't get that if we attack each other.\",\n",
        "    0.5725,\n",
        "    '-1']\n",
        "]\n",
        "\n",
        "twoscoresumfast_result = [\n",
        "    ['comment',\n",
        "    'imldado',\n",
        "    '2qhma',\n",
        "    'newzealand',\n",
        "    'false',\n",
        "    '1661990327',\n",
        "    'https://old.reddit.com/r/newzealand/comments/x28xci/long_rant_pessimistic_asf_and_feel_like_were/imldado/',\n",
        "    \"I'm honestly waiting for climate change and the impacts of that to kick some fucking sense into people. But who am I kidding itll still just be more of the poor suffering while the rich claim victim hood for handouts while letting us all starve. Its honestly hard some days to not just give up, and I truly wonder if and when anything will ever actually be done.\",\n",
        "    -0.1143,\n",
        "    '1'],\n",
        "    ['comment',\n",
        "    'imld6cb',\n",
        "    '2qi09',\n",
        "    'sacramento',\n",
        "    'false',\n",
        "    '1661990278',\n",
        "    'https://old.reddit.com/r/Sacramento/comments/x2ruqy/hey_guyz_this_is_a_tough_one_why_do_you_think/imld6cb/',\n",
        "    \"Not just Sacramento. It's actually happening all over the world. Climate change is real, believe it or not.\",\n",
        "    0.0,\n",
        "    '4']\n",
        "]\n",
        "\n",
        "@pytest.fixture(scope='session')\n",
        "def dataset():\n",
        "    data = read_csv(arquivo)\n",
        "    search = Searcher(data)\n",
        "    return search\n",
        "\n",
        "def test_get_comment_from_id(dataset):\n",
        "    '''\n",
        "    Testa a função get_comment_from_id dado um id válido\n",
        "    '''\n",
        "    assert dataset.get_comment_from_id('imld6cb') == ['comment',\n",
        "                                                      'imld6cb',\n",
        "                                                      '2qi09',\n",
        "                                                      'sacramento',\n",
        "                                                      'false',\n",
        "                                                      '1661990278',\n",
        "                                                      'https://old.reddit.com/r/Sacramento/comments/x2ruqy/hey_guyz_this_is_a_tough_one_why_do_you_think/imld6cb/',\n",
        "                                                      \"Not just Sacramento. It's actually happening all over the world. Climate change is real, believe it or not.\",\n",
        "                                                      0.0,\n",
        "                                                      '4']\n",
        "\n",
        "def test_get_comment_from_id_notfound(dataset):\n",
        "    '''\n",
        "    Testa a função get_comment_from_id dado um id inválido\n",
        "    '''\n",
        "    assert dataset.get_comment_from_id('aabb1122') == None\n",
        "\n",
        "def test_get_comment_from_id_fast(dataset):\n",
        "    '''\n",
        "    Testa a função get_comment_from_id_fast dado um id válido\n",
        "    '''\n",
        "    assert dataset.get_comment_from_id_fast('imld6cb') == ['comment',\n",
        "                                                           'imld6cb',\n",
        "                                                           '2qi09',\n",
        "                                                           'sacramento',\n",
        "                                                           'false',\n",
        "                                                           '1661990278',\n",
        "                                                           'https://old.reddit.com/r/Sacramento/comments/x2ruqy/hey_guyz_this_is_a_tough_one_why_do_you_think/imld6cb/',\n",
        "                                                           \"Not just Sacramento. It's actually happening all over the world. Climate change is real, believe it or not.\",\n",
        "                                                           0.0,\n",
        "                                                           '4']\n",
        "\n",
        "def test_get_comment_from_id_fast_notfound(dataset):\n",
        "    '''\n",
        "    Testa a função get_comment_from_id_fast dado um id inválido\n",
        "    '''\n",
        "    assert dataset.get_comment_from_id_fast('aabb1122') == None\n",
        "\n",
        "def test_get_sentiment_in_range(dataset):\n",
        "    '''\n",
        "    Testa a função get_sentiment_in_range dado um range qualquer\n",
        "    '''\n",
        "    assert len(dataset.get_sentiment_in_range(-0.0101, -0.01)) == 54\n",
        "\n",
        "def test_twoScoreSum(dataset):\n",
        "\n",
        "    assert dataset.twoScoreSum(1) == twoscoresum_result\n",
        "\n",
        "# def test_twoScoreSum_notfound(dataset):\n",
        "\n",
        "#     assert dataset.twoScoreSum(50000) == -1\n",
        "\n",
        "def test_twoScoreSum_fast(dataset):\n",
        "\n",
        "    assert dataset.twoScoreSum_fast(5) == twoscoresumfast_result\n",
        "\n",
        "def test_twoScoreSum_fast_notfound(dataset):\n",
        "\n",
        "    assert dataset.twoScoreSum_fast(50000) == -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDrw2T9qO8Vo",
        "outputId": "2b2bc0cb-2a03-4eb1-94b6-39e46f625267"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest test_data.py -vv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJmN-3QoXmMc",
        "outputId": "a45ff961-3a27-4eeb-d518-8b8687c80291"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.14, pytest-3.6.4, py-1.11.0, pluggy-0.7.1 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 8 items                                                             \u001b[0m\u001b[1m\rcollected 8 items                                                              \u001b[0m\n",
            "\n",
            "test_data.py::test_get_comment_from_id \u001b[32mPASSED\u001b[0m\u001b[36m                            [ 12%]\u001b[0m\n",
            "test_data.py::test_get_comment_from_id_notfound \u001b[32mPASSED\u001b[0m\u001b[36m                   [ 25%]\u001b[0m\n",
            "test_data.py::test_get_comment_from_id_fast \u001b[32mPASSED\u001b[0m\u001b[36m                       [ 37%]\u001b[0m\n",
            "test_data.py::test_get_comment_from_id_fast_notfound \u001b[32mPASSED\u001b[0m\u001b[36m              [ 50%]\u001b[0m\n",
            "test_data.py::test_get_sentiment_in_range \u001b[32mPASSED\u001b[0m\u001b[36m                         [ 62%]\u001b[0m\n",
            "test_data.py::test_twoScoreSum \u001b[32mPASSED\u001b[0m\u001b[36m                                    [ 75%]\u001b[0m\n",
            "test_data.py::test_twoScoreSum_fast \u001b[32mPASSED\u001b[0m\u001b[36m                               [ 87%]\u001b[0m\n",
            "test_data.py::test_twoScoreSum_fast_notfound \u001b[32mPASSED\u001b[0m\u001b[36m                      [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m\u001b[1m========================== 8 passed in 116.46 seconds ==========================\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}